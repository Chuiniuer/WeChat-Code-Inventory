{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a518d9f5-54e2-4d37-9b4c-95e7bbf322aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "# from unet import build_unet\n",
    "# from metrics import dice_loss, dice_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788e8afb-239c-4a7c-bf11-6aaee84a7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"E:\\l3\\dynamic landslide prediction\\Revision Round1\\selected_solution\\feature_matrix\\training_data_cnn_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad49f8b-8f28-4ca2-aaf4-662ce165528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"dis2fault\"] = (data[\"dis2fault\"]-4.7755097e05) / 5.229909e05\n",
    "data[\"GEM_RT475y\"] = (data[\"GEM_RT475y\"]-(-4.649508e02)) / 3.875843e03\n",
    "data[\"elevation\"] = (data[\"elevation\"]-1.581916e02) / 3.958743e03\n",
    "data[\"slope\"] = (data[\"slope\"]-(-4.542834e02)) / 3.850408e03\n",
    "data[\"dis2river\"] = (data[\"dis2river\"]-1.357943e04) / 2.763065e04\n",
    "data[\"NDVI\"] = (data[\"NDVI\"]-2323.23796253) / 8138.420801119\n",
    "data[\"pr\"] = (data[\"pr\"]-19.02047875) / 32.9010473645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4a31d4-33fc-47a9-9720-8a2ae85a8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"dis2fault\", \"GEM_RT475y\", \"elevation\", \"slope\", \"dis2river\", \"NDVI\", \"pr\", \"lithology\", \"landcover\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681f1673-2d65-48b5-82ed-80a77742a515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dis2fault</th>\n",
       "      <th>GEM_RT475y</th>\n",
       "      <th>elevation</th>\n",
       "      <th>slope</th>\n",
       "      <th>dis2river</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>pr</th>\n",
       "      <th>lithology</th>\n",
       "      <th>landcover</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>475888.000000</td>\n",
       "      <td>475888.000000</td>\n",
       "      <td>475888.000000</td>\n",
       "      <td>475888.000000</td>\n",
       "      <td>475888.000000</td>\n",
       "      <td>475888.000000</td>\n",
       "      <td>475888.000000</td>\n",
       "      <td>475888.000000</td>\n",
       "      <td>475888.000000</td>\n",
       "      <td>475888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.054309</td>\n",
       "      <td>0.119982</td>\n",
       "      <td>0.111954</td>\n",
       "      <td>0.119602</td>\n",
       "      <td>-0.100489</td>\n",
       "      <td>0.238054</td>\n",
       "      <td>2.999740</td>\n",
       "      <td>10.321569</td>\n",
       "      <td>10.436502</td>\n",
       "      <td>0.333299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.975630</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.175786</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.799732</td>\n",
       "      <td>0.311634</td>\n",
       "      <td>7.320184</td>\n",
       "      <td>2.485272</td>\n",
       "      <td>2.799527</td>\n",
       "      <td>0.471393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.912779</td>\n",
       "      <td>0.119965</td>\n",
       "      <td>-0.040718</td>\n",
       "      <td>0.117983</td>\n",
       "      <td>-0.487153</td>\n",
       "      <td>-0.528909</td>\n",
       "      <td>-91.669437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.827685</td>\n",
       "      <td>0.119971</td>\n",
       "      <td>-0.014952</td>\n",
       "      <td>0.118167</td>\n",
       "      <td>-0.429651</td>\n",
       "      <td>-0.027609</td>\n",
       "      <td>-0.146514</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.341656</td>\n",
       "      <td>0.119976</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.118724</td>\n",
       "      <td>-0.330825</td>\n",
       "      <td>0.241052</td>\n",
       "      <td>1.643702</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.296065</td>\n",
       "      <td>0.119989</td>\n",
       "      <td>0.191174</td>\n",
       "      <td>0.120389</td>\n",
       "      <td>-0.085049</td>\n",
       "      <td>0.513683</td>\n",
       "      <td>5.683087</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.042389</td>\n",
       "      <td>0.120188</td>\n",
       "      <td>1.280661</td>\n",
       "      <td>0.132667</td>\n",
       "      <td>9.978787</td>\n",
       "      <td>0.862610</td>\n",
       "      <td>29.445249</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dis2fault     GEM_RT475y      elevation          slope  \\\n",
       "count  475888.000000  475888.000000  475888.000000  475888.000000   \n",
       "mean       -0.054309       0.119982       0.111954       0.119602   \n",
       "std         0.975630       0.000017       0.175786       0.001961   \n",
       "min        -0.912779       0.119965      -0.040718       0.117983   \n",
       "25%        -0.827685       0.119971      -0.014952       0.118167   \n",
       "50%        -0.341656       0.119976       0.050725       0.118724   \n",
       "75%         0.296065       0.119989       0.191174       0.120389   \n",
       "max         4.042389       0.120188       1.280661       0.132667   \n",
       "\n",
       "           dis2river           NDVI             pr      lithology  \\\n",
       "count  475888.000000  475888.000000  475888.000000  475888.000000   \n",
       "mean       -0.100489       0.238054       2.999740      10.321569   \n",
       "std         0.799732       0.311634       7.320184       2.485272   \n",
       "min        -0.487153      -0.528909     -91.669437       0.000000   \n",
       "25%        -0.429651      -0.027609      -0.146514      10.000000   \n",
       "50%        -0.330825       0.241052       1.643702      11.000000   \n",
       "75%        -0.085049       0.513683       5.683087      12.000000   \n",
       "max         9.978787       0.862610      29.445249      16.000000   \n",
       "\n",
       "           landcover          label  \n",
       "count  475888.000000  475888.000000  \n",
       "mean       10.436502       0.333299  \n",
       "std         2.799527       0.471393  \n",
       "min         0.000000       0.000000  \n",
       "25%         9.000000       0.000000  \n",
       "50%        10.000000       0.000000  \n",
       "75%        12.000000       1.000000  \n",
       "max        17.000000       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598e9a21-fc28-438a-8c45-f2792b21c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = np.array(data).T.reshape(10, int(len(data)/49), 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "122ca930-64f2-4dd0-92d2-7242152ddf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = data_input.transpose(1, 2, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d60ae8-d801-4fc1-953a-b41f4ed97d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9712, 7, 7, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1425223a-dbad-491d-b3a0-dea7234ec49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_input[:, :, :, :-1]\n",
    "y = data_input[:, 3, 3, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22edea26-25f4-487d-9119-c4840ddd3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the feature and target data into training and validation sets using a 80-20 split ratio.\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4add71d4-aa40-4480-b467-99a23344a91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5827, 7, 7, 9), (5827,), (1942, 7, 7, 9), (1942,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d5c6a8e-5bb6-493e-a9cd-6c12f1bf7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, Activation, MaxPool2D,\n",
    "                                     Conv2DTranspose, Concatenate, GlobalAveragePooling2D, Resizing)\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    # 上采样\n",
    "    x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(inputs)\n",
    "\n",
    "    # 获取 skip 的空间尺寸\n",
    "    skip_shape = tf.keras.backend.int_shape(skip_features)\n",
    "    target_height, target_width = skip_shape[1], skip_shape[2]\n",
    "\n",
    "    # Resize x 和 skip_features 到相同尺寸\n",
    "    x = Resizing(target_height, target_width, interpolation='bilinear')(x)\n",
    "    skip_resized = Resizing(target_height, target_width, interpolation='bilinear')(skip_features)\n",
    "\n",
    "    # 拼接并卷积\n",
    "    x = Concatenate()([skip_resized, x])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def compute_max_depth(h, w):\n",
    "    depth = 0\n",
    "    while h >= 2 and w >= 2:\n",
    "        h //= 2\n",
    "        w //= 2\n",
    "        depth += 1\n",
    "    return depth\n",
    "\n",
    "def build_dynamic_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    H, W = input_shape[0], input_shape[1]\n",
    "    max_depth = min(4, compute_max_depth(H, W))  # 最多4层\n",
    "\n",
    "    encoder_outputs = []\n",
    "    x = inputs\n",
    "\n",
    "    filters = [64, 128, 256, 512, 1024]\n",
    "\n",
    "    # Encoder\n",
    "    for i in range(max_depth):\n",
    "        x, p = encoder_block(x, filters[i])\n",
    "        encoder_outputs.append(x)\n",
    "        x = p\n",
    "\n",
    "    # Bottleneck\n",
    "    x = conv_block(x, filters[max_depth])\n",
    "\n",
    "    # Decoder\n",
    "    for i in reversed(range(max_depth)):\n",
    "        x = decoder_block(x, encoder_outputs[i], filters[i])\n",
    "\n",
    "    # 输出层\n",
    "    x = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    model = Model(inputs, x, name=\"UNet-Auto-NoLambda\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85969449-3c24-4e32-97e0-3090f9298af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d35d334-8948-4a7d-b156-4d8f2d66860d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8513 - loss: 0.3758\n",
      "Epoch 1: val_loss improved from inf to 0.35078, saving model to E:\\phd_l1\\微信公众号\\20250504_UNET\\model.keras\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - accuracy: 0.8513 - loss: 0.3756 - val_accuracy: 0.8687 - val_loss: 0.3508 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m182/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8671 - loss: 0.3025\n",
      "Epoch 2: val_loss improved from 0.35078 to 0.29698, saving model to E:\\phd_l1\\微信公众号\\20250504_UNET\\model.keras\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - accuracy: 0.8671 - loss: 0.3024 - val_accuracy: 0.8795 - val_loss: 0.2970 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8764 - loss: 0.2739\n",
      "Epoch 3: val_loss improved from 0.29698 to 0.29076, saving model to E:\\phd_l1\\微信公众号\\20250504_UNET\\model.keras\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.8764 - loss: 0.2739 - val_accuracy: 0.8785 - val_loss: 0.2908 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8933 - loss: 0.2445\n",
      "Epoch 4: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.8933 - loss: 0.2445 - val_accuracy: 0.8759 - val_loss: 0.3131 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9053 - loss: 0.2213\n",
      "Epoch 5: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9053 - loss: 0.2213 - val_accuracy: 0.8702 - val_loss: 0.3332 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9140 - loss: 0.2017\n",
      "Epoch 6: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.9140 - loss: 0.2016 - val_accuracy: 0.8620 - val_loss: 0.3323 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m182/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9283 - loss: 0.1699\n",
      "Epoch 7: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.9283 - loss: 0.1699 - val_accuracy: 0.8630 - val_loss: 0.3442 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9289 - loss: 0.1719\n",
      "Epoch 8: val_loss did not improve from 0.29076\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9290 - loss: 0.1718 - val_accuracy: 0.8532 - val_loss: 0.3635 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m181/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9431 - loss: 0.1433\n",
      "Epoch 9: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9433 - loss: 0.1429 - val_accuracy: 0.8728 - val_loss: 0.3560 - learning_rate: 1.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9610 - loss: 0.1052\n",
      "Epoch 10: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9611 - loss: 0.1051 - val_accuracy: 0.8754 - val_loss: 0.3759 - learning_rate: 1.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m182/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9695 - loss: 0.0883\n",
      "Epoch 11: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9696 - loss: 0.0882 - val_accuracy: 0.8718 - val_loss: 0.3944 - learning_rate: 1.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m182/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9757 - loss: 0.0744\n",
      "Epoch 12: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9757 - loss: 0.0743 - val_accuracy: 0.8718 - val_loss: 0.4120 - learning_rate: 1.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m181/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9826 - loss: 0.0621\n",
      "Epoch 13: val_loss did not improve from 0.29076\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9826 - loss: 0.0620 - val_accuracy: 0.8723 - val_loss: 0.4285 - learning_rate: 1.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m181/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9880 - loss: 0.0506\n",
      "Epoch 14: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9880 - loss: 0.0505 - val_accuracy: 0.8744 - val_loss: 0.4307 - learning_rate: 1.0000e-06\n",
      "Epoch 15/200\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9891 - loss: 0.0485\n",
      "Epoch 15: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9891 - loss: 0.0485 - val_accuracy: 0.8744 - val_loss: 0.4323 - learning_rate: 1.0000e-06\n",
      "Epoch 16/200\n",
      "\u001b[1m181/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9891 - loss: 0.0472\n",
      "Epoch 16: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9891 - loss: 0.0471 - val_accuracy: 0.8754 - val_loss: 0.4344 - learning_rate: 1.0000e-06\n",
      "Epoch 17/200\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9901 - loss: 0.0459\n",
      "Epoch 17: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9901 - loss: 0.0458 - val_accuracy: 0.8759 - val_loss: 0.4367 - learning_rate: 1.0000e-06\n",
      "Epoch 18/200\n",
      "\u001b[1m181/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9905 - loss: 0.0447\n",
      "Epoch 18: val_loss did not improve from 0.29076\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9905 - loss: 0.0446 - val_accuracy: 0.8754 - val_loss: 0.4390 - learning_rate: 1.0000e-06\n",
      "Epoch 19/200\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9905 - loss: 0.0433\n",
      "Epoch 19: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9905 - loss: 0.0432 - val_accuracy: 0.8749 - val_loss: 0.4403 - learning_rate: 1.0000e-07\n",
      "Epoch 20/200\n",
      "\u001b[1m181/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9905 - loss: 0.0431\n",
      "Epoch 20: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9905 - loss: 0.0431 - val_accuracy: 0.8754 - val_loss: 0.4407 - learning_rate: 1.0000e-07\n",
      "Epoch 21/200\n",
      "\u001b[1m181/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9905 - loss: 0.0430\n",
      "Epoch 21: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9905 - loss: 0.0430 - val_accuracy: 0.8754 - val_loss: 0.4410 - learning_rate: 1.0000e-07\n",
      "Epoch 22/200\n",
      "\u001b[1m181/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9905 - loss: 0.0429\n",
      "Epoch 22: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.9905 - loss: 0.0428 - val_accuracy: 0.8754 - val_loss: 0.4412 - learning_rate: 1.0000e-07\n",
      "Epoch 23/200\n",
      "\u001b[1m181/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9905 - loss: 0.0427\n",
      "Epoch 23: val_loss did not improve from 0.29076\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.9905 - loss: 0.0427 - val_accuracy: 0.8754 - val_loss: 0.4415 - learning_rate: 1.0000e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25a0447a050>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入形状为你当前使用的 (7, 7, 9)\n",
    "input_shape = (7, 7, 9)\n",
    "\n",
    "\"\"\" Seeding \"\"\"\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\"\"\" Directory for storing files \"\"\"\n",
    "create_dir(\"files\")\n",
    "\n",
    "\"\"\" Hyperparameters \"\"\"\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "num_epochs = 200\n",
    "model_path = \"E:\\\\phd_l1\\\\微信公众号\\\\20250504_UNET\\\\model.keras\"\n",
    "csv_path = \"E:\\\\phd_l1\\\\微信公众号\\\\20250504_UNET\\\\log.csv\"\n",
    "\n",
    "\"\"\" Model \"\"\"\n",
    "model = build_dynamic_unet(input_shape)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr), metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "    CSVLogger(csv_path),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train, \n",
    "    epochs=num_epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fab143dd-d2a5-4daf-ae3e-a2f56f2532a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.config.enable_unsafe_deserialization()\n",
    "best_model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "376aca89-b124-42c8-845d-d06d1b463d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "Accuracy: 0.8739\n",
      "Precision: 0.8260\n",
      "Recall: 0.7864\n",
      "F1-score: 0.8057\n",
      "AUC: 0.9475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 预测\n",
    "y_pred_prob = best_model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # 将概率转换为二进制标签\n",
    "\n",
    "# 计算各项评估指标\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98233d-bcb0-4da0-bee0-31772a8c8114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
